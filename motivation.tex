\section{Motivation}
\label{sec:motivation}

\subsection{The Challenge Facing Internet Providers}

Modern edge applications operate under strict end-to-end latency SLOs, often ranging from tens to hundreds of milliseconds. However, real-world deployments consistently fail to meet these guarantees due to:

Resource contention at edge compute nodes (CPU/GPU) and access networks.

Heterogeneous workloads, where latency-critical and best-effort applications compete for limited resources.

SLO-unaware schedulers, which optimize fairness or throughput rather than deadline satisfaction.

Operational fragmentation, where access networks and edge compute are owned and managed by different entities, making coordinated solutions impractical.

For ISPs, these issues translate into degraded Quality of Experience (QoE), difficulty offering premium low-latency services, and inefficient over-provisioning to compensate for unpredictability.



\subsection{Limitations of Existing Approaches}
Existing approaches fall into three broad categories:

Network-layer or RAN-specific solutions, which require tight coordination with applications or compute platforms and are difficult to deploy in multi-operator environments.

Cloud-centric SLO-aware schedulers, which assume stable network latency and react too slowly for edge-scale, millisecond-level deadlines.

Application-specific optimizations, which do not generalize across workloads or access technologies.

As demonstrated by our recent work on 5G MEC, even sophisticated SLO-aware designs break down when coordination delays, heterogeneous applications, and compute contention are present.